---
title: "DDSCaseStudy2"
author: "Stuart Miller"
date: "August 16, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, load-data, echo=FALSE, message=FALSE, warning=FALSE}
## Computation Setup

# import libraries
library(knitr)
library(tidyverse)
library(GGally)
library(gridExtra)
library(RColorBrewer)
library(gplots)
library(corrplot)
library(ggthemes)
library(caret)

set.seed(3456)

# import helper functions
source('../analysis/helper/data_munging.R')
source('../analysis/helper/visual.R')


# read in data
train <- read_csv('../analysis/data/CaseStudy2-data_train.csv')

# create a vector of numeric features
features.numeric <- c('DailyRate', 'DistanceFromHome', 'Age', 'HourlyRate', 'MonthlyIncome', 'MonthlyRate',
           'NumCompaniesWorked','PercentSalaryHike', 'TotalWorkingYears', 'TrainingTimesLastYear',
           'YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion', 'YearsWithCurrManager')

# create a vector of numeric features
features.factor <- c('BusinessTravel', 'Department', 'Education', 'EducationField', 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'OverTime', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'WorkLifeBalance')

# create a vector of numeric features
features.factor <- c('BusinessTravel', 'Department', 'Education', 'EducationField', 'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'OverTime', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'WorkLifeBalance')

# factor categorical variables
train[, features.factor] <- lapply(train[, features.factor], as.factor)
```

# Executive Summary

In this analysis, we present factors related to attrition.
Three top factors are presented and relations to other factors are described.
Models for attrition and income are presented along with a discussion on performance.
Results of the income modeling are interpreted.
Finally, some other trends in the data are described.

# Introduction

Attrition is costly. Attrition presents loss of talent and manpower, which often results in schedule delays, loss of productivity, and
costs of hiring new talent. In this analysis, we examine a dataset employee attributes with attrition labels to find attributes
associated with attrition and create a predictive model for attrition. First, the top factors associated with attrition will be
presented and explained. Then, a predictive model will be shown and explained. Additionally, a predictive model for income will be
presented. The income predictor was a special request along with the main analysis. Lastly, an interesting trends found in the data
will be reported.

# Attrition Analysis

The data science team as identified three top factors that are associated with employee attrition.
These factors are addressed individually below. 
Additionally, the associations between these factors and other variables are discussed.

## Top Three Factors

The top three factors associated with attrition are

* Job Involvement
* Work-Life Balance
* Job Level

### Job Involvement

#### Overview of Impact on Attrition

Nearly 50% of employees rating their job involement at 1 are leaving the company.
The lowest level job involvement is substantially higher than the other job involvement levels.

```{r, jobinv-primary, echo=FALSE, fig.align="center"}
train %>% ggplot(aes(x = JobInvolvement, fill = Attrition)) +
  geom_bar(position = 'fill') +
  coord_flip() + 
  ggtitle("Attrition Proportion vs Job Involvement") +
  xlab('Job Involvement') +
  ylab('Attrition Proportion') +
  scale_fill_few(palette = 'Dark') + 
  theme_few()
```

#### Impact on Job Roles

Almost all job roles show high attrition with low job involvement.
The roles **human resources, research scientist, sales executive, sales representative,
Manager, healthcare representative, and laboratory technician**
attrition for the lowest job involvement.
Notibly, attrition rates of Sales Representative, Manufacturing Director,
and Research Director do not seem to be affected by job involvement.

```{r, jobinv-jobroles, echo=FALSE, fig.align="center"}
train %>% ggplot(aes(x = JobInvolvement, fill = Attrition)) +
  geom_bar(position = 'fill') +
  coord_flip() +
  facet_wrap( ~ JobRole) + 
  ggtitle("Attrition Proportion vs Job Involvement for Job Roles") +
  xlab('Job Involvement') +
  ylab('Attrition Proportion') +
  scale_fill_few(palette = 'Dark') + 
  theme_few()
```

#### Impact on Job Level

Attriton is high for all job levels where job invovlement is low. 
The attrition rate is especially high (over 50%) in level 1 and 5.

```{r, jobinv-joblevel, echo=FALSE, fig.align="center"}
train %>% ggplot(aes(x = JobInvolvement, fill = Attrition)) +
  geom_bar(position = 'fill') +
  coord_flip() +
  facet_wrap( ~ JobLevel) + 
  ggtitle("Attrition Proportion vs Job Involvement for Job Levels") +
  xlab('Job Involvement') +
  ylab('Attrition Proportion') +
  scale_fill_few(palette = 'Dark') + 
  theme_few()
```

### Work-Life Balance

Approximate 35% of employees rating their work-life balance at 1 are leaving the company.
The lowest level work-life balance is substantially higher than the other job involvement levels.

```{r, worklife-primary, echo=FALSE, fig.align="center"}
train %>% ggplot(aes(x = WorkLifeBalance, fill = Attrition)) +
  geom_bar(position = 'fill') +
  coord_flip() + 
  ggtitle("Attrition Proportion vs Work-Life Balance") +
  xlab('Work-Life Balance') +
  ylab('Attrition Proportion') +
  scale_fill_few(palette = 'Dark') + 
  theme_few()
```

#### Impact on Job Roles

The attrition rate for laboratory technicians and sales executives is especially high
for employees reporting low work-life balance, approximately  75% and 60% respectively.
The attration rate for sales representative seems usual on this chart. This is because it
it unusually high compared to all other roles and is likely driven by something else.

```{r, worklife-jobroles, echo=FALSE, fig.align="center"}
train %>% ggplot(aes(x = WorkLifeBalance, fill = Attrition)) +
  geom_bar(position = 'fill') +
  coord_flip() +
  facet_wrap( ~ JobRole) + 
  ggtitle("Attrition Proportion vs Work-Life Balance for Job Roles") +
  xlab('Work-Life Balance') +
  ylab('Attrition Proportion') +
  scale_fill_few(palette = 'Dark') + 
  theme_few()
```

#### Impact on Job Levels

Plotting the propriton of attrition by work-life balance rating for job levels shows
that generally lower rating of work-life balance correlate with high attrtion rate.

```{r, worklife-joblevels, echo=FALSE, fig.align="center"}
train %>% ggplot(aes(x = WorkLifeBalance, fill = Attrition)) +
  geom_bar(position = 'fill') +
  coord_flip() +
  facet_wrap( ~ JobLevel) + 
  ggtitle("Attrition Proportion vs Work-Life Balance for Job Levels") +
  xlab('Work-Life Balance') +
  ylab('Attrition Proportion') + 
  scale_fill_few(palette = 'Dark') + 
  theme_few()
```

### Overtime

Approximate 35% of employees performing overtime work are leaving the company.
The attrition rate for overtime workers is substantially higher than employees not working overtime.

```{r, overtime-primary, echo=FALSE, fig.align="center"}
train %>% ggplot(aes(x = OverTime, fill = Attrition)) +
  geom_bar(position = 'fill') +
  coord_flip() + 
  ggtitle("Attrition Proportion vs Overtime") +
  xlab('Overtime') +
  ylab('Attrition Proportion') +
  scale_fill_few(palette = 'Dark') + 
  theme_few()
```

#### Job Role Interaction

The roles human resources, research scientist, sales executive, sales representative,
Manager, healthcare representative, and laboratory technician all show high attrition 
rates for overtime workers.

```{r, overtime-jobroles, echo=FALSE, fig.align="center"}
train %>% ggplot(aes(x = OverTime, fill = Attrition)) +
  geom_bar(position = 'fill') +
  coord_flip() +
  facet_wrap( ~ JobRole) + 
  scale_fill_few(palette = 'Dark') + 
  theme_few()
```

#### Job Level Interaction

Overtime workers with a job level of 1 are showing very high attrition rates (above 50%).

```{r, overtime-joblevels, echo=FALSE, fig.align="center"}
train %>% ggplot(aes(x = OverTime, fill = Attrition)) +
  geom_bar(position = 'fill') +
  coord_flip() +
  facet_wrap( ~ JobLevel) + 
  scale_fill_few(palette = 'Dark') + 
  theme_few()
```

## Sales Representative Attrition

Sales representative have a very high attrition rate, nearly 50%. This is much higher than al other roles, which are below 25%.

```{r, salesrep-attrit, echo=FALSE, fig.align="center"}
train %>% ggplot(aes(x = JobRole, fill = Attrition)) +
  geom_bar(position = 'fill') +
  coord_flip() + 
  scale_fill_few(palette = 'Dark') + 
  theme_few()
```

Sales representatives also general have to shortest tenure at the company and the fewest total working years on average.

```{r, salesrep-attrit-years, echo=FALSE, warning=FALSE, message=FALSE, fig.align="center"}
train %>% 
  ggplot(aes(x = JobRole,
             y = YearsAtCompany,
             fill = JobRole)) +
  geom_boxplot() + 
  scale_fill_few(palette = 'Dark') + 
  theme_few() + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

train %>% 
  ggplot(aes(x = JobRole,
             y = TotalWorkingYears,
             fill = JobRole)) +
  geom_boxplot() + 
  scale_fill_few(palette = 'Dark') + 
  theme_few() + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

# Other Interesting Trend

There appears to be a correlation between years worked at the company and years in current role,
years with current manager, and years since last promotion.
This correlation appears to be almost linear. However, a linear regression does not meet the required assumptions.


```{r, message=FALSE}
p1 <- train %>% filter(YearsAtCompany > 0) %>%
  ggplot(aes(x = YearsWithCurrManager, y = YearsAtCompany)) + 
  geom_point() + geom_smooth(method = 'lm')
p2 <- train %>% filter(YearsAtCompany > 0) %>%
  ggplot(aes(x = YearsInCurrentRole, y = YearsAtCompany)) + 
  geom_point() + geom_smooth(method = 'lm')
grid.arrange(p1,p2, ncol = 2)

```



# Modeling

The data science team was tasked with modeling two features of the dataset: employee attrition and employee income.

## Attrition Modeling

Prediction of attrition was attempted with naive bayes.
The target was to create a model with at least 60% specificity and 60% sensitivity.
A large number of variables that appeared to be significant for attrition prediction were included.
The model performance metrics are listed below in the top table.
The results of the model predictions are listed in the second table.

Based on the preformance of the model, the goals for sensitivity and specificity were met. 

```{r, attritonmodel-data, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# read in data
train <- read_csv('../analysis/data/CaseStudy2-data_train.csv')

set.seed(3456)

# create a vector of numeric features
features.numeric <- c('DailyRate', 'DistanceFromHome', 'Age', 'HourlyRate', 'MonthlyIncome', 'MonthlyRate',
           'NumCompaniesWorked','PercentSalaryHike', 'TotalWorkingYears', 'TrainingTimesLastYear',
           'YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion', 'YearsWithCurrManager')

# create a vector of numeric features
features.factor <- c('BusinessTravel', 'Department', 'Education', 'EducationField', 'EnvironmentSatisfaction',
                     'Gender', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus',
                     'OverTime', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',
                     'WorkLifeBalance')

# create a vector of numeric features
features.factor <- c('BusinessTravel', 'Department', 'Education', 'EducationField', 'EmployeeNumber',
                     'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel', 'JobRole',
                     'JobSatisfaction', 'MaritalStatus', 'OverTime', 'PerformanceRating',
                     'RelationshipSatisfaction', 'StockOptionLevel', 'WorkLifeBalance')

# factor categorical variables
train[, features.factor] <- lapply(train[, features.factor], as.factor)


# split off a test set
trainIndex <- createDataPartition(train$MonthlyIncome , p = .75, 
                                  list = FALSE, 
                                  times = 1)
dfTrain <- train[trainIndex,]
dfTest <-  train[-trainIndex,]

# factor releveling - based on EDA
train$Attrition <- as.factor(train$Attrition)

train$JobInvolvement <- recode(train$JobInvolvement, '3' = '2', '4' = '2')
train$EnvironmentSatisfaction <- recode(train$EnvironmentSatisfaction, '3' = '2', '4' = '2')
train$WorkLifeBalance <- recode(train$WorkLifeBalance, '3' = '2', '4' = '2')
train$StockOptionLevel <- recode(train$StockOptionLevel, '0' = '3', '1' = '2')
train$Education <- recode(train$Education, '2' = '1', '3' = '1', '4' = '1')
train$JobLevel <- recode(train$JobLevel,  '2' = '5', '3' = '5')
train$JobRole <- as.factor(recode(train$JobRole, "Sales Representative" = 3,
                                        "Research Scientist" = 2,
                                        "Sales Executive" = 2,
                                        "Human Resources" = 2,
                                        "Laboratory Technician" = 2,
                                        "Manufacturing Director" = 1,
                                        "Research Director" = 1,
                                        "Manager" = 1,
                                        "Healthcare Representative" = 1))
train$BusinessTravel <- recode(train$BusinessTravel, "Non-Travel" = "Travel_Rarely" )
train$EducationField <- recode(train$EducationField,
                              "Technical Degree" = '1',
                              "Human Resources"  = '1',
                              "Life Sciences"    = '2',
                              "Marketing"        = '3',
                              "Medical"          = '2',
                              "Other"            = '3')
train$JobSatisfaction <- recode(train$JobSatisfaction,
                                '3' = '1',
                                '2' = '1')

# train the model
# Set up repeated k-fold cross-validation
train.control <-trainControl(method = "repeatedcv",
                             number = 5,
                             repeats = 5,
                             summaryFunction = twoClassSummary,
                             classProbs = TRUE)
# Train the model
model.cv <-train(y = dfTrain$Attrition,
                 x = dfTrain[, c('OverTime' ,
                                 'JobInvolvement' ,
                                 'EnvironmentSatisfaction',
                                 'WorkLifeBalance' ,
                                 'StockOptionLevel' ,
                                 'Age',
                                 'YearsInCurrentRole', 
                                 'YearsAtCompany',
                                 'JobLevel',
                                 'JobRole',
                                 'TotalWorkingYears',
                                 'MonthlyIncome',
                                 'DistanceFromHome',
                                 'YearsWithCurrManager')],
                 method = 'nb',
                 metric = 'Spec',
                 trControl = train.control)
# print model summary
model.cv

```

**Model Performance**

```{r, validation, warning=FALSE, echo=FALSE}

preds <- predict(model.cv, dfTest[, !names(dfTest) %in% ('Attrition')])

h <- confusionMatrix(table(preds, dfTest$Attrition))


kable(data.frame(
  'Specificity' = c(h$byClass[['Specificity']]),
  'Sensitivity' = c(h$byClass[['Sensitivity']])
))
```

**Model Prediction on Test Set**

```{r, echo=FALSE}
kable(data.frame(
  'Predicted Attrition' = c(h$table[2,2]),
  'Missed Attrition' = c(h$table[1,2])
))
```


## Income Modeling

Income was modeled with linear regression (OLS). Modeling with other models, such as KNN, was attempted,
but linear regression provided the best model with interpretable results.
A discussion on the model construction and validation is given below.

```{r, incomemodel-data, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# read in data
train <- read_csv('../analysis/data/CaseStudy2-data_train.csv')

# create a vector of numeric features
features.numeric <- c('DailyRate', 'DistanceFromHome', 'Age', 'HourlyRate', 'MonthlyIncome', 'MonthlyRate',
           'NumCompaniesWorked','PercentSalaryHike', 'TotalWorkingYears', 'TrainingTimesLastYear',
           'YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion', 'YearsWithCurrManager')

# create a vector of numeric features
features.factor <- c('BusinessTravel', 'Department', 'Education', 'EducationField', 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'OverTime', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'WorkLifeBalance')

# create a vector of numeric features
features.factor <- c('BusinessTravel', 'Department', 'Education', 'EducationField', 'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'OverTime', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'WorkLifeBalance')

# factor categorical variables
train[, features.factor] <- lapply(train[, features.factor], as.factor)

# split off a test set
trainIndex <- createDataPartition(train$MonthlyIncome , p = .75, 
                                  list = FALSE, 
                                  times = 1)
dfTrain <- train[trainIndex,]
dfTest <-  train[-trainIndex,]

# CV Runner - cross validate model on traning parition
train.cv <- function(model, method, folds){
  # Set up repeated k-fold cross-validation
  train.control <-trainControl(method = "cv", number = folds)
  # Train the model
  model.cv <-dfTrain %>% train(model,
                   data = .,
                   method = method,
                   trControl = train.control)
  # print model summary
  model.cv
}

# nominal fit for assessment plots
model.linear <- dfTrain %>% lm(MonthlyIncome ~ TotalWorkingYears + JobLevel + JobRole , data = .)

summary(model.linear)



model.formula <- MonthlyIncome ~ JobLevel + JobRole + TotalWorkingYears

# Eval model on 5 folds
lin.model.cv <- train.cv(model.formula, 'lm', 5)

# print model summary
lin.model.cv
```


### Model Construction

From EDA, it appears that monthly income is correlated to `TotalworkingYears`, `Age`, `YearsAtCompany`, `YearsInCurrentRole`, and `YearsWithCurrentManager`.

From the factors:

* `JobLevel` appears to partion `TotalWorkingYears` and `MonthlyIncome` very well.
* `JobRole` appears to partion `MonthlyIncome` very well.

Based on EDA and feature selection, the following model will be used for linear regression:

$$ \mu \lbrace MonthlyIncome \rbrace = \hat\beta_0 + \hat\beta_1 (JobLevel) + \hat\beta_2(JobRole) + \hat\beta_3(TotalWorkingYears) $$

### Model Assessment

#### Assessment Plots

The model was trained with the entired dataset. The trained model was used to generate assessment plots.

* The QQ plot and histogram of residuals do not appear to provide evidence against the assumption of normality.
* While there may be some hints against the assumption of constant variance, the violations do not appear to be egregious as around 5% of studentized residuals are expected to be outside $\pm 2$.
* The sampling procedure is not know so independence cannot be assessed. We will assume it is true and continue with caution.

```{r, incomemodel-assessment-plots, incomemodel-assessmentplots, echo=FALSE, fig.align="center"}
dfTrain  %>% basic.fit.plots(., model.linear)
```

#### Cross Validation and External Validation

The model was validated in two ways cross validation and external validation. 
Internal validation was used as an initial screening method on tentative models.
The cross validation RMSE value ofr this model is shown in the table under `RMSE.Train`.
Once well preforming models were chosen, the final model model was selected by 
running the models on an external validation set (unseen data). 
The external validation RMSE score is shown in the table below as `RMSE.Test`.
An estimate of the variation in income explained by this model is also given in the 
table as `Adj.R.Square`.

```{r, incomemodel-validation, echo=FALSE}
# helper function for calculating model performance
RMSE <- function(model, df){
  predictions <- predict(model, df)
  sqrt(mean((df$MonthlyIncome - predictions)^2))
}

lin.test.RMSE <- RMSE(lin.model.cv, dfTest)
lin.train.RMSE <- RMSE(lin.model.cv, dfTrain)

kable(data.frame(
  RMSE.Test = c(lin.test.RMSE),
  RMSE.Train = c(lin.train.RMSE),
  'Adj R Square' = c(lin.model.cv$results$Rsquared)
))
```

### Model Interpretation

The model requires that all categorical variables have the same slope between `MonthlyIncome` and `TotalWorkingYears`
becasue no interaction terms were included. 
The categorical variables only provide a difference in intercept for the regression between `MonthlyIncome` and `TotalWorkingYears`.

The estimates and p-values from the model fit are shown below. 
We find that for an incease in total working years of one year there is an associated increase in mean monthly income of $44.46.
The change in intercept for each job level appears to be significantly different (level 1 was used for reference).
The change in intercept for each job role appears to be significantly different except for manufacturing director and sales executive.
There is not sufficent evidence to suggest that the intercepts for manufacturing director and sales executive
are significantly different than the reference (Healthcare Representative).



| Variable                          | Estimate   |  p-value   |
|-----------------------------------|------------|------------|
| (Intercept)                  |  3561.09      |  < 2e-16  |
| Total Working Years            |    44.46    | 8.04e-07  |
| Job Level 2                    |  1742.46    |  < 2e-16  |
| Job Level 3                    |  4893.21    |  < 2e-16  |
| Job Level 4                    |  8191.81    |  < 2e-16  |
| Job Level 5                    | 10960.61    |  < 2e-16  |
| Job Role: Human Resources       |  -984.80    |  0.00084 |
| Job Role: Laboratory Technician | -1163.75    | 1.75e-08 |
| Job Role: Manager               |  3436.58    |  < 2e-16 |
| Job Role: Manufacturing Director|   153.28    |  0.40279 |
| Job Role: Research Director     |  3562.03    |  < 2e-16 |
| Job Role: Research Scientist    |  -981.12    | 2.40e-06 |
| Job Role: Sales Executive       |   -40.24    |  0.79983 |
| Job Role: Sales Representative  | -1220.67    | 1.71e-06 |

# Appendix

## Session Info

The session info output for is file is provided in the codebook (`./CodeBook.md`).
The session info was generated by calling `SessionInfo()` on the completion of knitting this `Rmd` file.

